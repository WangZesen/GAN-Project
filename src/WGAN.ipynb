{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "batch_size = 10\n",
    "z_dim = 128\n",
    "learning_rate_gen = 5e-5\n",
    "learning_rate_dis = 5e-5\n",
    "max_step = 20000\n",
    "n_dis = 5\n",
    "# lambda (gradient panelty)\n",
    "lam = 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters = 64):\n",
    "    conv1 = tf.layers.conv2d(x, \n",
    "                             filters = filters,\n",
    "                             kernel_size = 3,\n",
    "                             strides = 1,\n",
    "                             padding = 'same')\n",
    "    conv1 = tf.layers.batch_normalization(conv1)\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(conv1,\n",
    "                             filters = filters,\n",
    "                             kernel_size = 3,\n",
    "                             strides = 1,\n",
    "                             padding = 'same')\n",
    "    conv2 = tf.layers.batch_normalization(conv2)\n",
    "    \n",
    "    return tf.add(x, conv2)\n",
    "\n",
    "def pixel_shuffle(I, r):\n",
    "    bsize, a, b, c = I.get_shape().as_list()\n",
    "    X = tf.reshape(I, (bsize, a, b, r, r))\n",
    "    X = tf.split(X, a, 1)  # a, [bsize, b, r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], 2)  # bsize, b, a*r, r\n",
    "    X = tf.split(X, b, 1)  # b, [bsize, a*r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], 2)  # bsize, a*r, b*r\n",
    "    return tf.reshape(X, (bsize, a*r, b*r, 1))\n",
    "\n",
    "def PS(X, r):\n",
    "    # Main OP that you can arbitrarily use in you tensorflow code\n",
    "    Xc = tf.split(X, X.get_shape()[3] // (r ** 2), 3)\n",
    "    # if self.is_train:\n",
    "    X = tf.concat([pixel_shuffle(x, r) for x in Xc], 3)\n",
    "\n",
    "    #    X = tf.concat([pixel_shuffle_test(x, r) for x in Xc], 3)\n",
    "    return X\n",
    "\n",
    "def resize_block(x, filters):\n",
    "    out = tf.layers.conv2d(x,\n",
    "                           filters = filters,\n",
    "                           kernel_size = 3,\n",
    "                           strides = 1,\n",
    "                           padding = 'same')\n",
    "    out = PS(out, 2)\n",
    "    out = tf.layers.batch_normalization(out)\n",
    "    return tf.nn.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Generator Network\n",
    "def generator(x, reuse = False):\n",
    "    with tf.variable_scope('generator', reuse = reuse):\n",
    "        fc1 = tf.layers.dense(x, \n",
    "                              units = 6 * 6 * 256, \n",
    "                              activation = tf.nn.leaky_relu)\n",
    "        fc1 = tf.layers.batch_normalization(fc1)\n",
    "        fc1 = tf.reshape(fc1, [-1, 6, 6, 256])\n",
    "\n",
    "        # First Convolutional Layer\n",
    "        conv1 = tf.layers.conv2d_transpose(fc1, \n",
    "                                           filters = 128, \n",
    "                                           kernel_size = 5,\n",
    "                                           strides = 2,\n",
    "                                           padding = 'same',\n",
    "                                           activation = tf.nn.leaky_relu)\n",
    "        conv1 = tf.layers.batch_normalization(conv1)\n",
    "\n",
    "        res_blocks = []\n",
    "        res_blocks.append(conv1)\n",
    "        for i in range(6):\n",
    "            res_blocks.append(residual_block(res_blocks[i], filters = 128))\n",
    "            \n",
    "            \n",
    "        resize1 = resize_block(res_blocks[-1], filters = 128)\n",
    "        resize2 = resize_block(resize1, filters = 64)\n",
    "        resize3 = resize_block(resize2, filters = 32)\n",
    "        \n",
    "        # Third Convolutional Layer (Output Layer with tanh activation)\n",
    "        output = tf.layers.conv2d_transpose(resize3, \n",
    "                                            filters = 3, \n",
    "                                            kernel_size = 9, \n",
    "                                            strides = 1,\n",
    "                                            padding = 'same',\n",
    "                                            activation = tf.nn.tanh)\n",
    "        print (output)\n",
    "        return output\n",
    "\n",
    "# test\n",
    "# z_input = tf.placeholder(tf.float32, shape = [None, z_dim], name = 'gen_input')\n",
    "# generator(z_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x, reuse = False):\n",
    "    with tf.variable_scope('discriminator', reuse = reuse):\n",
    "        \n",
    "        # conv1: 48 * 48 * 64\n",
    "        conv1 = tf.layers.conv2d(x,\n",
    "                                 filters = 64,\n",
    "                                 kernel_size = 5,\n",
    "                                 strides = 2,\n",
    "                                 padding = 'same',\n",
    "                                 activation = tf.nn.leaky_relu)\n",
    "        conv1 = tf.layers.batch_normalization(conv1)\n",
    "        \n",
    "        \n",
    "        # conv2: 24 * 24 * 64\n",
    "        conv2 = tf.layers.conv2d(conv1,\n",
    "                                 filters = 64,\n",
    "                                 kernel_size = 5,\n",
    "                                 strides = 2,\n",
    "                                 padding = 'same',\n",
    "                                 activation = tf.nn.leaky_relu)\n",
    "        conv2 = tf.layers.batch_normalization(conv2)\n",
    "        \n",
    "        # Residual Block 1\n",
    "        res1 = tf.layers.conv2d(conv2, \n",
    "                             filters = 64,\n",
    "                             kernel_size = 3,\n",
    "                             strides = 1,\n",
    "                             padding = 'same',\n",
    "                             activation = tf.nn.relu)\n",
    "        res1 = tf.layers.batch_normalization(res1)\n",
    "        res1_1 = tf.layers.conv2d(res1,\n",
    "                                 filters = 64,\n",
    "                                 kernel_size = 3,\n",
    "                                 strides = 1,\n",
    "                                 padding = 'same',\n",
    "                                 activation = tf.nn.relu)\n",
    "        res1_1 = tf.layers.batch_normalization(res1_1)\n",
    "        \n",
    "        res1_1 = tf.add(res1_1, conv2)\n",
    "        \n",
    "        # Residual Block 2\n",
    "        res2 = tf.layers.conv2d(res1_1, \n",
    "                             filters = 64,\n",
    "                             kernel_size = 3,\n",
    "                             strides = 1,\n",
    "                             padding = 'same',\n",
    "                             activation = tf.nn.relu)\n",
    "        res2 = tf.layers.batch_normalization(res2)\n",
    "        res2_1 = tf.layers.conv2d(res2,\n",
    "                                 filters = 64,\n",
    "                                 kernel_size = 3,\n",
    "                                 strides = 1,\n",
    "                                 padding = 'same',\n",
    "                                 activation = tf.nn.relu)\n",
    "        res2_1 = tf.layers.batch_normalization(res2_1)\n",
    "        res2_1 = tf.add(res2_1, res1_1)\n",
    "        \n",
    "        \n",
    "        # res2_1 = residual_block(conv2, filters = 64)\n",
    "        # res2_2 = residual_block(res2_1, filters = 64)\n",
    "        \n",
    "        # conv3: 12 * 12 * 64\n",
    "        conv3 = tf.layers.conv2d(res2_1,\n",
    "                                 filters = 64,\n",
    "                                 kernel_size = 5,\n",
    "                                 strides = 2,\n",
    "                                 padding = 'same',\n",
    "                                 activation = tf.nn.leaky_relu)\n",
    "        \n",
    "        conv3 = tf.layers.batch_normalization(conv3)\n",
    "        \n",
    "        # res3_1 = residual_block(conv3, filters = 64)\n",
    "        # res3_2 = residual_block(res3_1, filters = 64)\n",
    "        \n",
    "        \n",
    "        res3 = tf.layers.flatten(conv3)\n",
    "        \n",
    "        \n",
    "        # fc1: 128 units\n",
    "        fc1 = tf.layers.dense(res3, \n",
    "                              units = 128,\n",
    "                              activation = tf.nn.leaky_relu)\n",
    "        output = tf.layers.dense(fc1,\n",
    "                                units = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resize1: Tensor(\"generator/Relu_6:0\", shape=(10, 24, 24, 32), dtype=float32)\n",
      "resize2: Tensor(\"generator/Relu_7:0\", shape=(10, 48, 48, 16), dtype=float32)\n",
      "resize3: Tensor(\"generator/Relu_8:0\", shape=(10, 96, 96, 8), dtype=float32)\n",
      "Tensor(\"generator/conv2d_transpose_1/Tanh:0\", shape=(10, 96, 96, 3), dtype=float32)\n",
      "Tensor(\"generator/conv2d_transpose_1/Tanh:0\", shape=(10, 96, 96, 3), dtype=float32)\n",
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "gen_input = tf.placeholder(tf.float32, shape = [batch_size, z_dim], name = 'gen_input')\n",
    "dis_input = tf.placeholder(tf.float32, shape = [batch_size, 96, 96, 3], name = 'dis_input')\n",
    "fake_input = generator(gen_input)\n",
    "\n",
    "print (fake_input)\n",
    "\n",
    "# Logits\n",
    "true_logit = discriminator(dis_input)\n",
    "fake_logit = discriminator(fake_input, reuse = True)\n",
    "dis_loss = tf.reduce_mean(fake_logit - true_logit)\n",
    "gen_loss = tf.reduce_mean(- fake_logit)\n",
    "\n",
    "# Variables\n",
    "gen_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
    "dis_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "\n",
    "## Gradient Penalty\n",
    "\n",
    "# Generate Interpolated Samples\n",
    "uniform_dist = tf.contrib.distributions.Uniform(low=0., high=1.)\n",
    "alpha = uniform_dist.sample((batch_size, 1, 1, 1))\n",
    "interpolated = dis_input + alpha * (fake_input - dis_input)\n",
    "\n",
    "# Calculate Gradients\n",
    "int_logit = discriminator(interpolated, reuse = True)\n",
    "gradients = tf.gradients(int_logit, [interpolated, ])[0]\n",
    "gradients_l2 = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis = [1, 2, 3]))\n",
    "\n",
    "# Panelty\n",
    "gradient_penalty = lam * tf.reduce_mean(tf.square(gradients_l2 - 1.))\n",
    "dis_loss += gradient_penalty\n",
    "\n",
    "# Optimizer (RMSProp) RMSPropOptimizer\n",
    "gen_opt = tf.train.AdamOptimizer(learning_rate_gen).minimize(gen_loss, var_list = gen_var)\n",
    "dis_opt = tf.train.AdamOptimizer(learning_rate_dis).minimize(dis_loss, var_list = dis_var)\n",
    "\n",
    "# Initialization\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: 76.09224700927734, -0.004992236848920584, 76.48567199707031\n",
      "step 200: -77.4598159790039, -30.648754119873047, 7.34606409072876\n",
      "step 400: -70.12602996826172, 2.745579957962036, 7.2963995933532715\n",
      "step 600: -62.57015609741211, -0.05891614034771919, 7.75702428817749\n",
      "step 800: -68.90266418457031, 50.14519500732422, 10.044238090515137\n",
      "step 1000: -51.956974029541016, 39.60683059692383, 12.036355018615723\n",
      "step 1200: -39.3770866394043, 62.28644943237305, 3.605725049972534\n",
      "step 1400: -35.844425201416016, 96.47035217285156, 3.571990728378296\n",
      "step 1600: -50.82112503051758, 59.412086486816406, 3.3764374256134033\n",
      "step 1800: -31.55633544921875, 67.28782653808594, 1.2836687564849854\n",
      "step 2000: -35.508811950683594, 8.882211685180664, 2.9375905990600586\n",
      "step 2200: -31.189538955688477, 11.903844833374023, 2.4350178241729736\n",
      "step 2400: -26.37350082397461, -14.782821655273438, 3.0499672889709473\n",
      "step 2600: -37.594749450683594, 35.47789001464844, 3.8065853118896484\n",
      "step 2800: -40.911827087402344, 134.3104705810547, 2.49377179145813\n",
      "step 3000: -13.789783477783203, -46.563297271728516, 2.8875999450683594\n",
      "step 3200: -22.670360565185547, 89.15715789794922, 0.2148866057395935\n",
      "step 3400: -26.07134437561035, -18.558847427368164, 1.144252896308899\n",
      "step 3600: -32.11894607543945, 99.93687438964844, 2.311474561691284\n",
      "step 3800: -6.197207927703857, 23.689620971679688, 1.295520305633545\n",
      "step 4000: -18.942617416381836, -6.078121185302734, 1.2919654846191406\n",
      "step 4200: -20.151525497436523, 43.181785583496094, 0.5931529402732849\n",
      "step 4400: -28.09836769104004, -3.8786416053771973, 1.4208276271820068\n",
      "step 4600: -30.591999053955078, 40.32067108154297, 2.199962854385376\n",
      "step 4800: -18.4973201751709, 62.738914489746094, 1.840702772140503\n",
      "step 5000: -17.760461807250977, 103.60848236083984, 0.1700591742992401\n",
      "step 5200: -31.32391357421875, 98.95924377441406, 1.4882431030273438\n",
      "step 5400: -19.79011344909668, 15.683294296264648, 1.7567155361175537\n",
      "step 5600: 1.0586142539978027, -58.39073944091797, 0.43328726291656494\n",
      "step 5800: -24.458425521850586, -33.04046630859375, 1.5575107336044312\n",
      "step 6000: -14.959771156311035, 68.9566421508789, 0.4648507833480835\n",
      "step 6200: -20.03278923034668, -115.74165344238281, 1.7806631326675415\n",
      "step 6400: 3.1356520652770996, 67.58905029296875, 0.9833872318267822\n",
      "step 6600: -36.08406066894531, -63.5092658996582, 2.031731128692627\n",
      "step 6800: -3.507065534591675, -130.4068145751953, 0.05144678056240082\n",
      "step 7000: -22.15315818786621, 121.4144058227539, 0.36138707399368286\n",
      "step 7200: -13.045392990112305, -31.465612411499023, 4.579521179199219\n",
      "step 7400: -39.1266975402832, 84.64277648925781, 4.236544609069824\n",
      "step 7600: -42.483070373535156, 122.0259017944336, 0.5326979756355286\n",
      "step 7800: -11.446999549865723, -45.7996940612793, 0.6041960120201111\n",
      "step 8000: -23.816986083984375, 1.922837257385254, 2.060094118118286\n",
      "step 8200: -14.008098602294922, -62.2806396484375, 1.3075108528137207\n",
      "step 8400: -16.088777542114258, 96.22386169433594, 1.8262732028961182\n",
      "step 8600: -16.27781867980957, -50.08382797241211, 0.5078526735305786\n",
      "step 8800: -11.550050735473633, 121.4348373413086, 3.715510368347168\n",
      "step 9000: 2.402337074279785, -36.096981048583984, 1.3881924152374268\n",
      "step 9200: -20.819185256958008, -7.150369167327881, 0.9011183381080627\n",
      "step 9400: -3.9243369102478027, 10.520456314086914, 0.07116706669330597\n",
      "step 9600: -14.912307739257812, -36.30179977416992, 1.2551627159118652\n",
      "step 9800: -15.279783248901367, -11.815713882446289, 0.11492107063531876\n",
      "step 10000: -10.044413566589355, -25.58829689025879, 0.24461187422275543\n",
      "step 10200: -18.124710083007812, 16.85118865966797, 0.19695961475372314\n",
      "step 10400: -20.003793716430664, 14.894183158874512, 0.6859281063079834\n",
      "step 10600: -10.694472312927246, 126.6602554321289, 1.0593940019607544\n",
      "step 10800: -18.819177627563477, 158.5698699951172, 0.4903967082500458\n",
      "step 11000: -11.66759204864502, -18.888614654541016, 2.1245453357696533\n",
      "step 11200: -13.541290283203125, 91.60165405273438, 0.4194721579551697\n",
      "step 11400: -11.471951484680176, 12.167277336120605, 0.5232395529747009\n",
      "step 11600: -12.151640892028809, -53.99097442626953, 0.8964303731918335\n",
      "step 11800: -11.390620231628418, 87.7811050415039, 0.26679494976997375\n",
      "step 12000: -24.965015411376953, 51.57820510864258, 1.46831476688385\n",
      "step 12200: -7.5246100425720215, 86.95584869384766, 0.847008228302002\n",
      "step 12400: -16.371469497680664, 8.519909858703613, 0.8739291429519653\n",
      "step 12600: -20.57719612121582, 14.367985725402832, 0.638157069683075\n",
      "step 12800: -25.933155059814453, 86.82083892822266, 3.5340499877929688\n",
      "step 13000: -6.871290683746338, -160.8732147216797, 2.9745631217956543\n",
      "step 13200: -20.662256240844727, 46.64421463012695, 0.7849976420402527\n",
      "step 13400: 3.3565521240234375, -41.13956069946289, 1.616497278213501\n",
      "step 13600: -9.364103317260742, -44.77116394042969, 1.173466682434082\n",
      "step 13800: -10.466052055358887, 94.56867980957031, 3.3609418869018555\n",
      "step 14000: -13.47234058380127, 20.982421875, 0.2596127986907959\n",
      "step 14200: -25.241058349609375, -16.422176361083984, 0.5301060676574707\n",
      "step 14400: -12.188544273376465, -7.383265018463135, 0.45299017429351807\n",
      "step 14600: -2.474865198135376, 101.56035614013672, 0.6923298239707947\n",
      "step 14800: -6.194613933563232, -41.77702713012695, 0.22778449952602386\n",
      "step 15000: -15.88101863861084, -110.18910217285156, 0.5500078201293945\n",
      "step 15200: -16.2230281829834, 183.4204559326172, 2.9972643852233887\n",
      "step 15400: -23.518510818481445, -12.144308090209961, 0.8806087374687195\n",
      "step 15600: -8.844653129577637, -28.938045501708984, 0.4680049419403076\n",
      "step 15800: -9.255634307861328, -7.285174369812012, 0.223725825548172\n",
      "step 16000: -11.215112686157227, 13.436899185180664, 0.2946926951408386\n",
      "step 16200: -8.960012435913086, 8.594732284545898, 0.9007874131202698\n",
      "step 16400: -13.009099960327148, 23.756650924682617, 0.29263773560523987\n",
      "step 16600: -13.66240119934082, -29.969654083251953, 0.999225914478302\n",
      "step 16800: -5.938998222351074, 13.922945022583008, 0.20440077781677246\n",
      "step 17000: -16.450944900512695, 44.35976791381836, 0.5967264771461487\n",
      "step 17200: -21.672075271606445, 95.95906066894531, 1.0929542779922485\n",
      "step 17400: -10.783220291137695, -68.83549499511719, 0.6483845114707947\n",
      "step 17600: -11.221912384033203, 26.29366111755371, 0.149796724319458\n",
      "step 17800: -14.087671279907227, -43.78856658935547, 0.28480836749076843\n",
      "step 18000: -12.99695873260498, 47.91896057128906, 0.176666259765625\n",
      "step 18200: -17.609176635742188, -13.45732593536377, 1.211605191230774\n",
      "step 18400: -7.829128742218018, 14.63819694519043, 0.5240083336830139\n",
      "step 18600: -4.404683589935303, 47.18037033081055, 1.1386408805847168\n",
      "step 18800: 1.9998712539672852, -41.579830169677734, 0.46426260471343994\n",
      "step 19000: -10.551529884338379, 17.544448852539062, 0.4214543402194977\n",
      "step 19200: -11.609013557434082, -18.665037155151367, 1.10905921459198\n",
      "step 19400: -11.427513122558594, -8.085532188415527, 0.7874981760978699\n",
      "step 19600: -7.2054901123046875, -40.266788482666016, 0.32829126715660095\n",
      "step 19800: -11.524639129638672, 17.765962600708008, 0.16441413760185242\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "from data_utils_batch import *\n",
    "data_X = dataReader('../data/animate/')\n",
    "\n",
    "model_dir = '../model/'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "for i in range(max_step):\n",
    "    \n",
    "    for j in range(n_dis):\n",
    "        batch_x = data_X.next_batch(batch_size)\n",
    "        batch_x = batch_x * 0.9\n",
    "        \n",
    "        z = np.random.normal(0., 0.5, size=[batch_size, z_dim])\n",
    "        feed_dict = {gen_input: z, dis_input: batch_x}\n",
    "        sess.run([dis_opt], feed_dict = feed_dict)\n",
    "        \n",
    "    batch_x = data_X.next_batch(batch_size)\n",
    "    batch_x = batch_x * 0.9\n",
    "    \n",
    "    z = np.random.normal(0., 0.5, size=[batch_size, z_dim])\n",
    "    feed_dict = {gen_input: z, dis_input: batch_x}\n",
    "    _, d_loss, g_loss, p = sess.run([gen_opt, dis_loss, gen_loss, gradient_penalty], feed_dict = feed_dict)\n",
    "    if i % 200 == 0:\n",
    "        print ('step {}: {}, {}, {}'.format(i, d_loss, g_loss, p))\n",
    "        saver.save(sess, model_dir + 'wgan', global_step = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9e3164a34224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Noise input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate images from noise, using the generator network.\n",
    "cnt = 0\n",
    "\n",
    "f, a = plt.subplots(8, 10, figsize=(10, 8))\n",
    "for i in range(10):\n",
    "    # Noise input.\n",
    "    z = np.random.normal(0., 0.5, size=[batch_size, z_dim])\n",
    "    g = sess.run(fake_input, feed_dict={gen_input: z})\n",
    "    \n",
    "    g[g > 0.9] = 0.9\n",
    "    g[g < -0.9] = -0.9\n",
    "    g = (g + 0.9) / 2. / 0.9\n",
    "    \n",
    "    batch_x = data_X.next_batch(batch_size)\n",
    "    batch_x = (batch_x + 1.) / 2.\n",
    "        \n",
    "    for j in range(4):\n",
    "        # Generate image from noise. Extend to 3 channels for matplot figure.\n",
    "        cv2.imwrite('../result/{}.jpg'.format(str(cnt).zfill(3)), g[j] * 255)\n",
    "        a[j][i].imshow(g[j])\n",
    "        a[j + 4][i].imshow(batch_x[j])\n",
    "        cnt += 1\n",
    "\n",
    "f.show()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
